{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# M5 Forecasting - Accuracy: LAMA Baseline\n",
        "\n",
        "**Course:** Light Auto ML  \n",
        "**Task:** Kaggle M5 Competition - Walmart Sales Forecasting  \n",
        "**Part 2:** Baseline Solution using LightAutoML (LAMA)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use LightAutoML library to create a baseline solution:\n",
        "- **Configuration 1:** Standard LAMA with default hyperparameters\n",
        "- **Configuration 2:** LAMA with custom hyperparameter tuning\n",
        "- **Evaluation:** Cross-validation metrics and test performance\n",
        "- **Comparison:** Select the best configuration\n",
        "\n",
        "## Installation Note\n",
        "\n",
        "```bash\n",
        "pip install lightautoml lightgbm xgboost catboost scikit-learn pandas numpy\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4.2\n"
          ]
        }
      ],
      "source": [
        "import lightautoml\n",
        "print(lightautoml.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightautoml in ./rapids-simple/lib/python3.11/site-packages (0.4.1)\n",
            "Requirement already satisfied: lightgbm in ./rapids-simple/lib/python3.11/site-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in ./rapids-simple/lib/python3.11/site-packages (2.1.4)\n",
            "Requirement already satisfied: catboost in ./rapids-simple/lib/python3.11/site-packages (1.2.8)\n",
            "Requirement already satisfied: scikit-learn in ./rapids-simple/lib/python3.11/site-packages (1.8.0)\n",
            "Requirement already satisfied: pandas in ./rapids-simple/lib/python3.11/site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in ./rapids-simple/lib/python3.11/site-packages (1.26.4)\n",
            "Requirement already satisfied: SQLAlchemy>=2.0 in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (2.0.45)\n",
            "Requirement already satisfied: autowoe>=1.3.3 in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (1.3.4)\n",
            "Requirement already satisfied: cmaes in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (0.12.0)\n",
            "Requirement already satisfied: holidays in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (0.87)\n",
            "Requirement already satisfied: jinja2 in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (3.1.6)\n",
            "Requirement already satisfied: joblib in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (1.5.3)\n",
            "Requirement already satisfied: json2html in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (1.3.0)\n",
            "Requirement already satisfied: networkx in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (3.6.1)\n",
            "Requirement already satisfied: optuna in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (4.6.0)\n",
            "Requirement already satisfied: poetry-core<2.0.0,>=1.0.0 in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (1.9.1)\n",
            "Requirement already satisfied: pyyaml in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (6.0.3)\n",
            "Requirement already satisfied: scipy in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (1.16.3)\n",
            "Requirement already satisfied: seaborn in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (0.13.2)\n",
            "Requirement already satisfied: statsmodels<=0.14.0 in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (0.14.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (2.0.1)\n",
            "Requirement already satisfied: tqdm in ./rapids-simple/lib/python3.11/site-packages (from lightautoml) (4.67.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in ./rapids-simple/lib/python3.11/site-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: patsy>=0.5.2 in ./rapids-simple/lib/python3.11/site-packages (from statsmodels<=0.14.0->lightautoml) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in ./rapids-simple/lib/python3.11/site-packages (from statsmodels<=0.14.0->lightautoml) (25.0)\n",
            "Requirement already satisfied: graphviz in ./rapids-simple/lib/python3.11/site-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in ./rapids-simple/lib/python3.11/site-packages (from catboost) (3.10.8)\n",
            "Requirement already satisfied: plotly in ./rapids-simple/lib/python3.11/site-packages (from catboost) (6.5.0)\n",
            "Requirement already satisfied: six in ./rapids-simple/lib/python3.11/site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.2.0 in ./rapids-simple/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./rapids-simple/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./rapids-simple/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./rapids-simple/lib/python3.11/site-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: StrEnum<0.5.0,>=0.4.7 in ./rapids-simple/lib/python3.11/site-packages (from autowoe>=1.3.3->lightautoml) (0.4.15)\n",
            "Requirement already satisfied: pytest in ./rapids-simple/lib/python3.11/site-packages (from autowoe>=1.3.3->lightautoml) (9.0.2)\n",
            "Requirement already satisfied: sphinx in ./rapids-simple/lib/python3.11/site-packages (from autowoe>=1.3.3->lightautoml) (8.2.3)\n",
            "Requirement already satisfied: sphinx-rtd-theme in ./rapids-simple/lib/python3.11/site-packages (from autowoe>=1.3.3->lightautoml) (3.0.2)\n",
            "Requirement already satisfied: greenlet>=1 in ./rapids-simple/lib/python3.11/site-packages (from SQLAlchemy>=2.0->lightautoml) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in ./rapids-simple/lib/python3.11/site-packages (from SQLAlchemy>=2.0->lightautoml) (4.15.0)\n",
            "Requirement already satisfied: filelock in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (3.20.1)\n",
            "Requirement already satisfied: sympy in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (1.14.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in ./rapids-simple/lib/python3.11/site-packages (from torch>=1.9.0->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: setuptools in ./rapids-simple/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->lightautoml) (80.9.0)\n",
            "Requirement already satisfied: wheel in ./rapids-simple/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->lightautoml) (0.45.1)\n",
            "Requirement already satisfied: cmake in ./rapids-simple/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.9.0->lightautoml) (4.2.0)\n",
            "Requirement already satisfied: lit in ./rapids-simple/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.9.0->lightautoml) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./rapids-simple/lib/python3.11/site-packages (from jinja2->lightautoml) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./rapids-simple/lib/python3.11/site-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in ./rapids-simple/lib/python3.11/site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./rapids-simple/lib/python3.11/site-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./rapids-simple/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in ./rapids-simple/lib/python3.11/site-packages (from matplotlib->catboost) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in ./rapids-simple/lib/python3.11/site-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: alembic>=1.5.0 in ./rapids-simple/lib/python3.11/site-packages (from optuna->lightautoml) (1.17.2)\n",
            "Requirement already satisfied: colorlog in ./rapids-simple/lib/python3.11/site-packages (from optuna->lightautoml) (6.10.1)\n",
            "Requirement already satisfied: Mako in ./rapids-simple/lib/python3.11/site-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.10)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in ./rapids-simple/lib/python3.11/site-packages (from plotly->catboost) (2.14.0)\n",
            "Requirement already satisfied: iniconfig>=1.0.1 in ./rapids-simple/lib/python3.11/site-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in ./rapids-simple/lib/python3.11/site-packages (from pytest->autowoe>=1.3.3->lightautoml) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in ./rapids-simple/lib/python3.11/site-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.19.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.32.5)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in ./rapids-simple/lib/python3.11/site-packages (from sphinx->autowoe>=1.3.3->lightautoml) (4.1.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./rapids-simple/lib/python3.11/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./rapids-simple/lib/python3.11/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rapids-simple/lib/python3.11/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (2.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./rapids-simple/lib/python3.11/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.3.3->lightautoml) (2025.11.12)\n",
            "Requirement already satisfied: roman-numerals==4.1.0 in ./rapids-simple/lib/python3.11/site-packages (from roman-numerals-py>=1.0.0->sphinx->autowoe>=1.3.3->lightautoml) (4.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in ./rapids-simple/lib/python3.11/site-packages (from sphinx-rtd-theme->autowoe>=1.3.3->lightautoml) (4.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./rapids-simple/lib/python3.11/site-packages (from sympy->torch>=1.9.0->lightautoml) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install lightautoml lightgbm xgboost catboost scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext-numpy2\n",
            "  Downloading fasttext_numpy2-0.10.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext-numpy2)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in ./rapids-simple/lib/python3.11/site-packages (from fasttext-numpy2) (80.9.0)\n",
            "Requirement already satisfied: numpy in ./rapids-simple/lib/python3.11/site-packages (from fasttext-numpy2) (1.26.4)\n",
            "Downloading fasttext_numpy2-0.10.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Installing collected packages: pybind11, fasttext-numpy2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [fasttext-numpy2]\n",
            "\u001b[1A\u001b[2KSuccessfully installed fasttext-numpy2-0.10.4 pybind11-3.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install fasttext-numpy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting click (from nltk)\n",
            "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: joblib in ./rapids-simple/lib/python3.11/site-packages (from nltk) (1.5.3)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Requirement already satisfied: tqdm in ./rapids-simple/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
            "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Installing collected packages: regex, click, nltk\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [nltk][32m2/3\u001b[0m [nltk]\n",
            "\u001b[1A\u001b[2KSuccessfully installed click-8.3.1 nltk-3.9.2 regex-2025.11.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'nlp' extra dependency package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
            "'nlp' extra dependency package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
            "'nlp' extra dependency package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
            "'nlp' extra dependency package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
            "Current time: 2025-12-20 22:46:07.386845\n",
            "Loading data...\n",
            "Sales data shape: (30490, 1947)\n",
            "Calendar data shape: (1969, 14)\n",
            "Prices data shape: (6841121, 4)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from datetime import datetime, timedelta\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# AutoML imports\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(f\"Current time: {datetime.now()}\")\n",
        "\n",
        "# Setup paths\n",
        "# DATA_PATH = Path('../input/m5-forecasting-accuracy')\n",
        "OUTPUT_PATH = Path('./models')\n",
        "OUTPUT_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Loading data...\")\n",
        "sales_train = pd.read_csv('sales_train_evaluation.csv')\n",
        "calendar = pd.read_csv('calendar.csv')\n",
        "prices = pd.read_csv('sell_prices.csv')\n",
        "\n",
        "print(f\"Sales data shape: {sales_train.shape}\")\n",
        "print(f\"Calendar data shape: {calendar.shape}\")\n",
        "print(f\"Prices data shape: {prices.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing data...\n"
          ]
        }
      ],
      "source": [
        "def prepare_advanced_features_fast(sales_train, calendar, prices, sample_products=100):\n",
        "    # -------- 0) Sampling (как у тебя) --------\n",
        "    if sample_products:\n",
        "        np.random.seed(42)\n",
        "        products = np.random.choice(sales_train['item_id'].unique(), sample_products, replace=False)\n",
        "        sales_train = sales_train[sales_train['item_id'].isin(products)].copy()\n",
        "\n",
        "    id_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
        "    date_cols = [c for c in sales_train.columns if c.startswith('d_')]\n",
        "\n",
        "    # Приведем ключи к category (часто ускоряет merge/groupby на повторяющихся строковых ключах)\n",
        "    for c in ['item_id', 'store_id', 'state_id', 'dept_id', 'cat_id']:\n",
        "        if c in sales_train.columns and sales_train[c].dtype != 'category':\n",
        "            sales_train[c] = sales_train[c].astype('category')\n",
        "\n",
        "    # -------- 1) Wide -> long быстрее через stack, чем melt на больших таблицах --------\n",
        "    # (melt делает больше аллокаций; stack часто быстрее для \"d_1..d_N\" формата) [web:41][web:39]\n",
        "    tmp = sales_train.set_index(id_cols)[date_cols]\n",
        "    sales_long = (tmp\n",
        "                  .stack(dropna=False)\n",
        "                  .rename('sales')\n",
        "                  .reset_index()\n",
        "                  .rename(columns={'level_6': 'day'}))  # level_6 зависит от числа id_cols; см. ниже примечание\n",
        "\n",
        "    # Если pandas назвал последний уровень иначе (например, 'level_6'), оставим универсально:\n",
        "    if 'day' not in sales_long.columns:\n",
        "        # последний столбец после reset_index — это day\n",
        "        sales_long = sales_long.rename(columns={sales_long.columns[len(id_cols)]: 'day'})\n",
        "\n",
        "    sales_long['day'] = sales_long['day'].str.slice(2).astype(np.int16)  # 'd_123' -> 123\n",
        "\n",
        "    # -------- 2) Calendar: сразу берём нужное + wm_yr_wk для корректного join с ценами --------\n",
        "    # В M5 цены меняются по wm_yr_wk, поэтому merge только по item/store создаёт many-to-many и тормозит. [web:49]\n",
        "    cal_cols = ['d', 'date']\n",
        "    if 'wm_yr_wk' in calendar.columns:\n",
        "        cal_cols.append('wm_yr_wk')\n",
        "\n",
        "    cal = calendar[cal_cols].copy()\n",
        "    cal['day'] = cal['d'].str.slice(2).astype(np.int16)\n",
        "    cal['date'] = pd.to_datetime(cal['date'])\n",
        "\n",
        "    # merge календаря (маленькая таблица — обычно не узкое место)\n",
        "    sales_long = sales_long.merge(cal.drop(columns=['d']), on='day', how='left')\n",
        "\n",
        "    # -------- 3) Prices: merge по item_id/store_id/wm_yr_wk (а не только по item/store) --------\n",
        "    if 'wm_yr_wk' in cal.columns and 'wm_yr_wk' in prices.columns:\n",
        "        price_cols = ['item_id', 'store_id', 'wm_yr_wk', 'sell_price']\n",
        "        p = prices[price_cols].copy()\n",
        "\n",
        "        # ключи к category тоже помогают на больших joins (не всегда, но часто)\n",
        "        for c in ['item_id', 'store_id']:\n",
        "            if p[c].dtype != 'category':\n",
        "                p[c] = p[c].astype('category')\n",
        "\n",
        "        sales_long = sales_long.merge(p, on=['item_id', 'store_id', 'wm_yr_wk'], how='left')\n",
        "    else:\n",
        "        # fallback: как у тебя, но предупреждение — может быть тяжело/неверно\n",
        "        price_cols = ['item_id', 'store_id', 'sell_price']\n",
        "        p = prices[price_cols].copy()\n",
        "        for c in ['item_id', 'store_id']:\n",
        "            if p[c].dtype != 'category':\n",
        "                p[c] = p[c].astype('category')\n",
        "        sales_long = sales_long.merge(p, on=['item_id', 'store_id'], how='left')\n",
        "\n",
        "    # -------- 4) Fill prices: один проход groupby вместо двух --------\n",
        "    # groupby().ffill().bfill() можно применять цепочкой; это типичный паттерн без apply/lambda. [web:10]\n",
        "    sales_long = sales_long.sort_values(['item_id', 'store_id', 'date'], kind='mergesort').reset_index(drop=True)\n",
        "\n",
        "    sales_long['sell_price'] = (sales_long\n",
        "                                .groupby(['item_id', 'store_id'], sort=False)['sell_price']\n",
        "                                .ffill()\n",
        "                                .bfill())\n",
        "\n",
        "    # финальный фоллбек\n",
        "    sales_long['sell_price'] = sales_long['sell_price'].fillna(sales_long['sell_price'].mean())\n",
        "\n",
        "    return sales_long\n",
        "\n",
        "print(\"\\nPreparing data...\")\n",
        "data = prepare_advanced_features_fast(sales_train, calendar, prices, sample_products=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>day</th>\n",
              "      <th>sales</th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>sell_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
              "      <td>FOODS_1_001</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
              "      <td>FOODS_1_001</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-30</td>\n",
              "      <td>11101</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
              "      <td>FOODS_1_001</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-31</td>\n",
              "      <td>11101</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
              "      <td>FOODS_1_001</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-02-01</td>\n",
              "      <td>11101</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
              "      <td>FOODS_1_001</td>\n",
              "      <td>FOODS_1</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-02-02</td>\n",
              "      <td>11101</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59181085</th>\n",
              "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
              "      <td>HOUSEHOLD_2_516</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>1937</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-18</td>\n",
              "      <td>11616</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59181086</th>\n",
              "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
              "      <td>HOUSEHOLD_2_516</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>1938</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-19</td>\n",
              "      <td>11616</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59181087</th>\n",
              "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
              "      <td>HOUSEHOLD_2_516</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>1939</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20</td>\n",
              "      <td>11616</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59181088</th>\n",
              "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
              "      <td>HOUSEHOLD_2_516</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>1940</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-21</td>\n",
              "      <td>11617</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59181089</th>\n",
              "      <td>HOUSEHOLD_2_516_WI_3_evaluation</td>\n",
              "      <td>HOUSEHOLD_2_516</td>\n",
              "      <td>HOUSEHOLD_2</td>\n",
              "      <td>HOUSEHOLD</td>\n",
              "      <td>WI_3</td>\n",
              "      <td>WI</td>\n",
              "      <td>1941</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-22</td>\n",
              "      <td>11617</td>\n",
              "      <td>5.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59181090 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       id          item_id      dept_id  \\\n",
              "0             FOODS_1_001_CA_1_evaluation      FOODS_1_001      FOODS_1   \n",
              "1             FOODS_1_001_CA_1_evaluation      FOODS_1_001      FOODS_1   \n",
              "2             FOODS_1_001_CA_1_evaluation      FOODS_1_001      FOODS_1   \n",
              "3             FOODS_1_001_CA_1_evaluation      FOODS_1_001      FOODS_1   \n",
              "4             FOODS_1_001_CA_1_evaluation      FOODS_1_001      FOODS_1   \n",
              "...                                   ...              ...          ...   \n",
              "59181085  HOUSEHOLD_2_516_WI_3_evaluation  HOUSEHOLD_2_516  HOUSEHOLD_2   \n",
              "59181086  HOUSEHOLD_2_516_WI_3_evaluation  HOUSEHOLD_2_516  HOUSEHOLD_2   \n",
              "59181087  HOUSEHOLD_2_516_WI_3_evaluation  HOUSEHOLD_2_516  HOUSEHOLD_2   \n",
              "59181088  HOUSEHOLD_2_516_WI_3_evaluation  HOUSEHOLD_2_516  HOUSEHOLD_2   \n",
              "59181089  HOUSEHOLD_2_516_WI_3_evaluation  HOUSEHOLD_2_516  HOUSEHOLD_2   \n",
              "\n",
              "             cat_id store_id state_id   day  sales       date  wm_yr_wk  \\\n",
              "0             FOODS     CA_1       CA     1      3 2011-01-29     11101   \n",
              "1             FOODS     CA_1       CA     2      0 2011-01-30     11101   \n",
              "2             FOODS     CA_1       CA     3      0 2011-01-31     11101   \n",
              "3             FOODS     CA_1       CA     4      1 2011-02-01     11101   \n",
              "4             FOODS     CA_1       CA     5      4 2011-02-02     11101   \n",
              "...             ...      ...      ...   ...    ...        ...       ...   \n",
              "59181085  HOUSEHOLD     WI_3       WI  1937      0 2016-05-18     11616   \n",
              "59181086  HOUSEHOLD     WI_3       WI  1938      0 2016-05-19     11616   \n",
              "59181087  HOUSEHOLD     WI_3       WI  1939      0 2016-05-20     11616   \n",
              "59181088  HOUSEHOLD     WI_3       WI  1940      0 2016-05-21     11617   \n",
              "59181089  HOUSEHOLD     WI_3       WI  1941      0 2016-05-22     11617   \n",
              "\n",
              "          sell_price  \n",
              "0               2.00  \n",
              "1               2.00  \n",
              "2               2.00  \n",
              "3               2.00  \n",
              "4               2.00  \n",
              "...              ...  \n",
              "59181085        5.94  \n",
              "59181086        5.94  \n",
              "59181087        5.94  \n",
              "59181088        5.94  \n",
              "59181089        5.94  \n",
              "\n",
              "[59181090 rows x 11 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating advanced features...\n",
            "Creating lag features...\n",
            "Creating rolling statistics...\n",
            "Creating trend features...\n",
            "Creating exponential smoothing features...\n",
            "Creating temporal features...\n",
            "Creating price features...\n",
            "Creating hierarchical aggregation features...\n",
            "Creating interaction features...\n",
            "Handling missing values...\n",
            "\n",
            "Feature engineering complete!\n",
            "Final dataset shape: (59181090, 57)\n",
            "\n",
            "Feature list (46 new features):\n",
            "  cat_avg_sales\n",
            "  cat_std_sales\n",
            "  day_of_month\n",
            "  day_of_week\n",
            "  dept_avg_sales\n",
            "  dept_std_sales\n",
            "  is_month_end\n",
            "  is_month_start\n",
            "  is_weekend\n",
            "  item_avg_sales\n",
            "  item_std_sales\n",
            "  month\n",
            "  price_change_30\n",
            "  price_change_7\n",
            "  price_lag_30\n",
            "  ... and 31 more\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "\n",
        "def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create advanced features for better model performance.\n",
        "\n",
        "    Оптимизированная версия:\n",
        "    - минимум transform+lambda (rolling без lambda)\n",
        "    - переиспользование groupby\n",
        "    - пакетное заполнение пропусков\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # ========= базовая подготовка / сортировка =========\n",
        "    df = df.sort_values(['item_id', 'store_id', 'date'], kind='mergesort').reset_index(drop=True)\n",
        "\n",
        "    # (опционально) ключи в category: память/скорость groupby\n",
        "    for col in ['item_id', 'store_id', 'dept_id', 'cat_id', 'state_id']:\n",
        "        if col in df.columns and df[col].dtype != 'category':\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    g = df.groupby(['item_id', 'store_id'], sort=False)\n",
        "    s = g['sales']\n",
        "\n",
        "    # helper: гарантируем числовой dtype для фич\n",
        "    def _to_f32(x):\n",
        "        return pd.to_numeric(x, errors='coerce', downcast='float').astype('float32')\n",
        "\n",
        "    # ============= LAG FEATURES =============\n",
        "    print(\"Creating lag features...\")\n",
        "    for lag in [7, 14, 30, 90]:\n",
        "        df[f'sales_lag_{lag}'] = s.shift(lag)\n",
        "\n",
        "    # ============= ROLLING STATISTICS =============\n",
        "    print(\"Creating rolling statistics...\")\n",
        "    for window in [7, 14, 30]:\n",
        "        r = s.rolling(window=window, min_periods=1)\n",
        "        df[f'sales_mean_{window}'] = _to_f32(r.mean().reset_index(drop=True))\n",
        "        df[f'sales_std_{window}']  = _to_f32(r.std().reset_index(drop=True))\n",
        "        df[f'sales_min_{window}']  = _to_f32(r.min().reset_index(drop=True))\n",
        "        df[f'sales_max_{window}']  = _to_f32(r.max().reset_index(drop=True))\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # ============= TREND FEATURES =============\n",
        "    print(\"Creating trend features...\")\n",
        "    for window in [7, 14, 30]:\n",
        "        lag_col = f'sales_lag_{window}'\n",
        "        df[f'sales_trend_{window}'] = _to_f32((df['sales'] - df[lag_col]) / (df[lag_col] + 1))\n",
        "\n",
        "    # ============= EXPONENTIAL SMOOTHING =============\n",
        "    print(\"Creating exponential smoothing features...\")\n",
        "    # В pandas нет прямого groupby.ewm как rolling; делаем проход по группам. [web:4]\n",
        "    for alpha in [0.2, 0.5]:\n",
        "        col_name = f'sales_ewm_{int(alpha * 10)}'\n",
        "        parts = []\n",
        "        for _, grp in g['sales']:\n",
        "            parts.append(grp.ewm(alpha=alpha, adjust=False).mean())\n",
        "        df[col_name] = _to_f32(pd.concat(parts).sort_index())\n",
        "\n",
        "    # ============= TEMPORAL FEATURES =============\n",
        "    print(\"Creating temporal features...\")\n",
        "    df['day_of_week'] = df['date'].dt.dayofweek.astype(np.int8)\n",
        "    df['month'] = df['date'].dt.month.astype(np.int8)\n",
        "    df['quarter'] = df['date'].dt.quarter.astype(np.int8)\n",
        "    df['day_of_month'] = df['date'].dt.day.astype(np.int8)\n",
        "    df['week_of_year'] = df['date'].dt.isocalendar().week.astype(np.int16)\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(np.int8)\n",
        "    df['is_month_start'] = (df['day_of_month'] <= 7).astype(np.int8)\n",
        "    df['is_month_end'] = (df['day_of_month'] >= 24).astype(np.int8)\n",
        "\n",
        "    # ============= PRICE FEATURES =============\n",
        "    print(\"Creating price features...\")\n",
        "    p = g['sell_price']\n",
        "    df['price_lag_7'] = p.shift(7)\n",
        "    df['price_lag_30'] = p.shift(30)\n",
        "\n",
        "    df['price_change_7'] = _to_f32(df['sell_price'] - df['price_lag_7'])\n",
        "    df['price_change_30'] = _to_f32(df['sell_price'] - df['price_lag_30'])\n",
        "\n",
        "    # FIX: безопасное выравнивание по строкам через transform (без set_index на неуникальном MultiIndex) [web:4]\n",
        "    df['price_rel_mean'] = _to_f32(df['sell_price'] / (p.transform('mean') + 1))\n",
        "\n",
        "    df['price_momentum'] = _to_f32((df['sell_price'] - p.shift(7)) / (p.shift(7) + 1))\n",
        "\n",
        "    # ============= HIERARCHICAL FEATURES =============\n",
        "    print(\"Creating hierarchical aggregation features...\")\n",
        "\n",
        "    item_stats = df.groupby('item_id', observed=True)['sales'].agg(['mean', 'std'])\n",
        "    df['item_avg_sales'] = _to_f32(df['item_id'].map(item_stats['mean']))\n",
        "    df['item_std_sales'] = _to_f32(df['item_id'].map(item_stats['std']))\n",
        "\n",
        "    store_stats = df.groupby('store_id', observed=True)['sales'].agg(['mean', 'std'])\n",
        "    df['store_avg_sales'] = _to_f32(df['store_id'].map(store_stats['mean']))\n",
        "    df['store_std_sales'] = _to_f32(df['store_id'].map(store_stats['std']))\n",
        "\n",
        "    cat_stats = df.groupby('cat_id', observed=True)['sales'].agg(['mean', 'std'])\n",
        "    df['cat_avg_sales'] = _to_f32(df['cat_id'].map(cat_stats['mean']))\n",
        "    df['cat_std_sales'] = _to_f32(df['cat_id'].map(cat_stats['std']))\n",
        "\n",
        "    dept_stats = df.groupby('dept_id', observed=True)['sales'].agg(['mean', 'std'])\n",
        "    df['dept_avg_sales'] = _to_f32(df['dept_id'].map(dept_stats['mean']))\n",
        "    df['dept_std_sales'] = _to_f32(df['dept_id'].map(dept_stats['std']))\n",
        "\n",
        "    # Store-category aggregation: FIX без pd.Series(MultiIndex) [web:68][web:106]\n",
        "    store_cat_mean = df.groupby(['store_id', 'cat_id'], observed=True)['sales'].mean()\n",
        "    key_sc = pd.MultiIndex.from_frame(df[['store_id', 'cat_id']])\n",
        "    df['store_cat_avg_sales'] = _to_f32(key_sc.map(store_cat_mean))\n",
        "\n",
        "    # ============= INTERACTION FEATURES =============\n",
        "    print(\"Creating interaction features...\")\n",
        "    df['price_sales_interaction'] = _to_f32(df['sell_price'] * df['sales_lag_7'].fillna(1))\n",
        "    df['store_item_interaction'] = _to_f32(df['store_avg_sales'] * df['item_avg_sales'])\n",
        "\n",
        "    # ============= FILL NaN VALUES =============\n",
        "    print(\"Handling missing values...\")\n",
        "\n",
        "    base_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id',\n",
        "                 'state_id', 'day', 'date', 'sales', 'sell_price']\n",
        "    base_cols = [c for c in base_cols if c in df.columns]\n",
        "    feature_cols = [c for c in df.columns if c not in base_cols]\n",
        "\n",
        "    if feature_cols:\n",
        "        df[feature_cols] = (df\n",
        "                            .groupby(['item_id', 'store_id'], sort=False)[feature_cols]\n",
        "                            .ffill()\n",
        "                            .bfill())\n",
        "        num_cols = df[feature_cols].select_dtypes(include=[np.number]).columns\n",
        "        if len(num_cols) > 0:\n",
        "            df[num_cols] = df[num_cols].fillna(df[num_cols].mean(numeric_only=True))\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\nFeature engineering complete!\")\n",
        "    print(f\"Final dataset shape: {df.shape}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# ==== вызов, как у тебя ====\n",
        "print(\"\\nCreating advanced features...\")\n",
        "data_features = create_advanced_features(data)\n",
        "\n",
        "print(f\"\\nFeature list ({len([c for c in data_features.columns if c not in data.columns])} new features):\")\n",
        "new_features = [c for c in data_features.columns if c not in data.columns]\n",
        "for feat in sorted(new_features)[:15]:\n",
        "    print(f\"  {feat}\")\n",
        "if len(new_features) > 15:\n",
        "    print(f\"  ... and {len(new_features) - 15} more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Splitting Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TRAIN-TEST SPLIT STRATEGY ===\n",
            "\n",
            "Training set:\n",
            "  Samples: 58,296,880\n",
            "  Date range: 2011-01-29 00:00:00 to 2016-04-23 00:00:00\n",
            "  Days: 0 to 1911\n",
            "\n",
            "Test set:\n",
            "  Samples: 884,210\n",
            "  Date range: 2016-04-24 00:00:00 to 2016-05-22 00:00:00\n",
            "  Days: 1912 to 1940\n",
            "\n",
            "Class distribution (target):\n",
            "  Train - Mean: 1.1261, Std: 3.8731\n",
            "  Test  - Mean: 1.4494, Std: 3.6468\n",
            "\n",
            "Feature columns (47):\n",
            "['sell_price', 'sales_lag_7', 'sales_lag_14', 'sales_lag_30', 'sales_lag_90', 'sales_mean_7', 'sales_std_7', 'sales_min_7', 'sales_max_7', 'sales_mean_14', 'sales_std_14', 'sales_min_14', 'sales_max_14', 'sales_mean_30', 'sales_std_30', 'sales_min_30', 'sales_max_30', 'sales_trend_7', 'sales_trend_14', 'sales_trend_30', 'sales_ewm_2', 'sales_ewm_5', 'day_of_week', 'month', 'quarter', 'day_of_month', 'week_of_year', 'is_weekend', 'is_month_start', 'is_month_end', 'price_lag_7', 'price_lag_30', 'price_change_7', 'price_change_30', 'price_rel_mean', 'price_momentum', 'item_avg_sales', 'item_std_sales', 'store_avg_sales', 'store_std_sales', 'cat_avg_sales', 'cat_std_sales', 'dept_avg_sales', 'dept_std_sales', 'store_cat_avg_sales', 'price_sales_interaction', 'store_item_interaction']\n",
            "\n",
            "Data prepared for LAMA:\n",
            "  X_train shape: (58296880, 47)\n",
            "  X_test shape: (884210, 47)\n",
            "  y_train shape: (58296880,)\n",
            "  y_test shape: (884210,)\n"
          ]
        }
      ],
      "source": [
        "print(\"=== TRAIN-TEST SPLIT STRATEGY ===\")\n",
        "\n",
        "# Time-based split (critical for time series to avoid data leakage)\n",
        "# We use the last 28 days for testing (competition period)\n",
        "\n",
        "data_features['date_num'] = (data_features['date'] - data_features['date'].min()).dt.days\n",
        "max_date_num = data_features['date_num'].max()\n",
        "min_test_date_num = max_date_num - 28  # Last 28 days = test set\n",
        "\n",
        "# Create train and test sets\n",
        "X_train = data_features[data_features['date_num'] < min_test_date_num].copy()\n",
        "X_test = data_features[data_features['date_num'] >= min_test_date_num].copy()\n",
        "\n",
        "y_train = X_train.pop('sales')\n",
        "y_test = X_test.pop('sales')\n",
        "\n",
        "print(f\"\\nTraining set:\")\n",
        "print(f\"  Samples: {len(X_train):,}\")\n",
        "print(f\"  Date range: {X_train['date'].min()} to {X_train['date'].max()}\")\n",
        "print(f\"  Days: {X_train['date_num'].min()} to {X_train['date_num'].max()}\")\n",
        "\n",
        "print(f\"\\nTest set:\")\n",
        "print(f\"  Samples: {len(X_test):,}\")\n",
        "print(f\"  Date range: {X_test['date'].min()} to {X_test['date'].max()}\")\n",
        "print(f\"  Days: {X_test['date_num'].min()} to {X_test['date_num'].max()}\")\n",
        "\n",
        "print(f\"\\nClass distribution (target):\")\n",
        "print(f\"  Train - Mean: {y_train.mean():.4f}, Std: {y_train.std():.4f}\")\n",
        "print(f\"  Test  - Mean: {y_test.mean():.4f}, Std: {y_test.std():.4f}\")\n",
        "\n",
        "# Identify feature columns\n",
        "feature_cols = [col for col in X_train.columns \n",
        "                if col not in ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', \n",
        "                              'state_id', 'day', 'date', 'date_num', 'wm_yr_wk']]\n",
        "\n",
        "print(f\"\\nFeature columns ({len(feature_cols)}):\")\n",
        "print(feature_cols)\n",
        "\n",
        "# Prepare data for LAMA (only numeric features)\n",
        "X_train_lama = X_train[feature_cols].copy()\n",
        "X_test_lama = X_test[feature_cols].copy()\n",
        "\n",
        "print(f\"\\nData prepared for LAMA:\")\n",
        "print(f\"  X_train shape: {X_train_lama.shape}\")\n",
        "print(f\"  X_test shape: {X_test_lama.shape}\")\n",
        "print(f\"  y_train shape: {y_train.shape}\")\n",
        "print(f\"  y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ## 4. Конфигурация LAMA 1: Проверка нескольких моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "int8       [day_of_week, month, quarter, day_of_month, is...\n",
              "int16                                         [week_of_year]\n",
              "float32    [sales_mean_7, sales_std_7, sales_min_7, sales...\n",
              "float64    [sell_price, sales_lag_7, sales_lag_14, sales_...\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols_by_dtype = X_train_lama.columns.to_series().groupby(X_train_lama.dtypes).apply(list)\n",
        "cols_by_dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURATION: LAMA 0.4.2 (memory-conscious, GPU)\n",
            "============================================================\n",
            "\n",
            "Training LAMA (memory-conscious)...\n",
            "[18:04:23] Stdout logging level is INFO.\n",
            "[18:04:23] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
            "[18:04:23] Task: reg\n",
            "\n",
            "[18:04:23] Start automl preset with listed constraints:\n",
            "[18:04:23] - time: 600.00 seconds\n",
            "[18:04:23] - CPU: 2 cores\n",
            "[18:04:23] - memory: 16 GB\n",
            "\n",
            "[18:04:23] \u001b[1mTrain data shape: (58296880, 48)\u001b[0m\n",
            "\n",
            "[18:04:57] Layer \u001b[1m1\u001b[0m train process start. Time left 566.52 secs\n",
            "[18:55:00] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
            "[18:55:05] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
            "[19:41:48] Time limit exceeded after calculating fold 0\n",
            "\n",
            "[19:41:48] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.04558352753520012\u001b[0m\n",
            "[19:41:48] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
            "[19:41:48] Time left -5245.13 secs\n",
            "\n",
            "[19:41:48] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
            "\n",
            "[19:41:48] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n",
            "[19:41:48] \u001b[1mAutoml preset training completed in 5845.16 seconds\u001b[0m\n",
            "\n",
            "[19:41:48] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (1 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
            "\n",
            "Training completed in 1:37:25.163053\n",
            "\n",
            "--- Results ---\n",
            "TRAIN:\n",
            "  RMSE: 0.1131\n",
            "  MAE:  0.0152\n",
            "  R2:   0.9991\n",
            "\n",
            "TEST:\n",
            "  RMSE: 0.0684\n",
            "  MAE:  0.0175\n",
            "  R2:   0.9996\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from lightautoml.tasks import Task\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURATION: LAMA 0.4.2 (memory-conscious, GPU)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for c in X_train_lama.columns:\n",
        "    if X_train_lama[c].dtype == \"float64\":\n",
        "        X_train_lama[c] = X_train_lama[c].astype(\"float32\")\n",
        "    elif X_train_lama[c].dtype == \"int64\":\n",
        "        X_train_lama[c] = X_train_lama[c].astype(\"int32\")\n",
        "\n",
        "for c in X_test_lama.columns:\n",
        "    if X_test_lama[c].dtype == \"float64\":\n",
        "        X_test_lama[c] = X_test_lama[c].astype(\"float32\")\n",
        "    elif X_test_lama[c].dtype == \"int64\":\n",
        "        X_test_lama[c] = X_test_lama[c].astype(\"int32\")\n",
        "\n",
        "task = Task(\"reg\", metric=\"mse\")  \n",
        "\n",
        "\n",
        "automl = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,        \n",
        "    gpu_ids=\"all\",\n",
        "    general_params={\n",
        "        \"use_algos\": [[\"cb\", \"lgb\"]],\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "TARGET_COL = \"__target__\"\n",
        "train_df = X_train_lama\n",
        "train_df[TARGET_COL] = np.asarray(y_train)\n",
        "\n",
        "roles = {\n",
        "    \"target\": TARGET_COL,\n",
        "    \"numeric\": [c for c in X_train_lama.columns if c != TARGET_COL],\n",
        "}\n",
        "\n",
        "print(\"\\nTraining LAMA (memory-conscious)...\")\n",
        "start_time = datetime.now()\n",
        "\n",
        "\n",
        "_ = automl.fit_predict(train_df, roles=roles, verbose=1) \n",
        "\n",
        "training_time = datetime.now() - start_time\n",
        "print(f\"Training completed in {training_time}\")\n",
        "\n",
        "\n",
        "X_train_for_pred = X_train_lama.drop(columns=[TARGET_COL])\n",
        "y_pred_train = automl.predict(X_train_for_pred).data.ravel()  \n",
        "y_pred_test = automl.predict(X_test_lama).data.ravel()        \n",
        "\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "rmse_test  = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "mae_train  = mean_absolute_error(y_train, y_pred_train)\n",
        "mae_test   = mean_absolute_error(y_test, y_pred_test)\n",
        "r2_train   = r2_score(y_train, y_pred_train)\n",
        "r2_test    = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\n--- Results ---\")\n",
        "print(\"TRAIN:\")\n",
        "print(f\"  RMSE: {rmse_train:.4f}\")\n",
        "print(f\"  MAE:  {mae_train:.4f}\")\n",
        "print(f\"  R2:   {r2_train:.4f}\")\n",
        "\n",
        "print(\"\\nTEST:\")\n",
        "print(f\"  RMSE: {rmse_test:.4f}\")\n",
        "print(f\"  MAE:  {mae_test:.4f}\")\n",
        "print(f\"  R2:   {r2_test:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lama_automl.joblib']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(automl, \"lama_automl.joblib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ## 5. LAMA Конфигурация 2: Улучшенная с подбором гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURATION 2: LAMA with Custom Hyperparameters\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create AutoML with extended timeout for deeper tuning\n",
        "automl_config2 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=900,  # 15 minutes (longer for better tuning)\n",
        "    cpu_limit=2,\n",
        "    gpu_ids=\"all\",     # использовать все доступные GPU [web:21]\n",
        "    general_params={\n",
        "        \"use_algos\": [[\"cb\", \"cb_tuned\"]],\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"\\nTraining LAMA Configuration 2...\")\n",
        "start_time = datetime.now()\n",
        "\n",
        "# Fit model with extended search\n",
        "_ = automl_config2.fit_predict(train_df, roles=roles, verbose=1)\n",
        "\n",
        "training_time_config2 = datetime.now() - start_time\n",
        "print(f\"Training completed in {training_time_config2}\")\n",
        "\n",
        "joblib.dump(automl_config2, \"lama_automl_config2.joblib\")\n",
        "# Make predictions\n",
        "y_pred_train_config2 = automl_config2.predict(X_train_lama).data.ravel()\n",
        "y_pred_test_config2 = automl_config2.predict(X_test_lama).data.ravel()\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_train_config2 = np.sqrt(mean_squared_error(y_train, y_pred_train_config2))\n",
        "rmse_test_config2 = np.sqrt(mean_squared_error(y_test, y_pred_test_config2))\n",
        "mae_train_config2 = mean_absolute_error(y_train, y_pred_train_config2)\n",
        "mae_test_config2 = mean_absolute_error(y_test, y_pred_test_config2)\n",
        "r2_train_config2 = r2_score(y_train, y_pred_train_config2)\n",
        "r2_test_config2 = r2_score(y_test, y_pred_test_config2)\n",
        "\n",
        "print(f\"\\n--- Configuration 2 Results ---\")\n",
        "print(f\"TRAIN SET:\")\n",
        "print(f\"  RMSE: {rmse_train_config2:.4f}\")\n",
        "print(f\"  MAE:  {mae_train_config2:.4f}\")\n",
        "print(f\"  R2:   {r2_train_config2:.4f}\")\n",
        "\n",
        "print(f\"\\nTEST SET:\")\n",
        "print(f\"  RMSE: {rmse_test_config2:.4f}\")\n",
        "print(f\"  MAE:  {mae_test_config2:.4f}\")\n",
        "print(f\"  R2:   {r2_test_config2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Проверка lama_automl.joblib (Config 1):\n",
            "TRAIN SET:\n",
            "  RMSE: 0.1131\n",
            "  MAE:  0.0152\n",
            "  R2:   0.9991\n",
            "\n",
            "TEST SET:\n",
            "  RMSE: 0.0684\n",
            "  MAE:  0.0175\n",
            "  R2:   0.9996\n",
            "\n",
            "--------------------------------------\n",
            "Проверка lama_automl_config2.joblib (Config 2):\n",
            "TRAIN SET:\n",
            "  RMSE: 0.5253\n",
            "  MAE:  0.0656\n",
            "  R2:   0.9816\n",
            "\n",
            "TEST SET:\n",
            "  RMSE: 0.3353\n",
            "  MAE:  0.0713\n",
            "  R2:   0.9915\n"
          ]
        }
      ],
      "source": [
        "# Загрузим сохранённые модели\n",
        "automl_loaded_default = joblib.load('lama_automl.joblib')\n",
        "automl_loaded_config2 = joblib.load('lama_automl_config2.joblib')\n",
        "\n",
        "# Проверим, что обе модели делают предсказания на наших данных\n",
        "\n",
        "print(\"Проверка lama_automl.joblib (Config 1):\")\n",
        "y_pred_train_loaded1 = automl_loaded_default.predict(X_train_lama).data.ravel()\n",
        "y_pred_test_loaded1 = automl_loaded_default.predict(X_test_lama).data.ravel()\n",
        "\n",
        "print(\"TRAIN SET:\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train_loaded1)):.4f}\")\n",
        "print(f\"  MAE:  {mean_absolute_error(y_train, y_pred_train_loaded1):.4f}\")\n",
        "print(f\"  R2:   {r2_score(y_train, y_pred_train_loaded1):.4f}\")\n",
        "\n",
        "print(\"\\nTEST SET:\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test_loaded1)):.4f}\")\n",
        "print(f\"  MAE:  {mean_absolute_error(y_test, y_pred_test_loaded1):.4f}\")\n",
        "print(f\"  R2:   {r2_score(y_test, y_pred_test_loaded1):.4f}\")\n",
        "\n",
        "print(\"\\n--------------------------------------\")\n",
        "\n",
        "print(\"Проверка lama_automl_config2.joblib (Config 2):\")\n",
        "y_pred_train_loaded2 = automl_loaded_config2.predict(X_train_lama).data.ravel()\n",
        "y_pred_test_loaded2 = automl_loaded_config2.predict(X_test_lama).data.ravel()\n",
        "\n",
        "print(\"TRAIN SET:\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_train_loaded2)):.4f}\")\n",
        "print(f\"  MAE:  {mean_absolute_error(y_train, y_pred_train_loaded2):.4f}\")\n",
        "print(f\"  R2:   {r2_score(y_train, y_pred_train_loaded2):.4f}\")\n",
        "\n",
        "print(\"\\nTEST SET:\")\n",
        "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test_loaded2)):.4f}\")\n",
        "print(f\"  MAE:  {mean_absolute_error(y_test, y_pred_test_loaded2):.4f}\")\n",
        "print(f\"  R2:   {r2_score(y_test, y_pred_test_loaded2):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Базовые результаты и дальнейшие шаги\n",
        "\n",
        "### Краткое резюме\n",
        "\n",
        "- **Конфигурация 1**: baseline LAMA с двумя моделями.\n",
        "- **Конфигурация 2**: облегчённый baseline запуск с тюнингом CatBoost (`cb_tuned`).\n",
        "\n",
        "**Выбор**: лучшая конфигурация — с минимальным Test RMSE.\n",
        "\n",
        "### Сравнение конфигураций\n",
        "\n",
        "| Metric        | Config 1   | Config 2   |\n",
        "|---------------|-----------|-----------|\n",
        "| Train RMSE    | 0.1131    | 0.5253    |\n",
        "| Test RMSE     | 0.0684    | 0.3353    |\n",
        "| Train MAE     | 0.0152    | 0.0656    |\n",
        "| Test MAE      | 0.0175    | 0.0713    |\n",
        "| Train R2      | 0.9991    | 0.9816    |\n",
        "| Test R2       | 0.9996    | 0.9915    |\n",
        "| Training Time | 1:37:25   | 0:45:33   |\n",
        "\n",
        "**Лучшая конфигурация**  \n",
        "Лучшая: конфигурация 1\n",
        "\n",
        "> **Причина:** ниже Test RMSE (лучше обобщает на тесте)\n",
        "\n",
        "**Модель сохранена:** `models/lama_baseline_best.pkl`\n",
        "\n",
        "### В чём “развитие” конфигурации 2\n",
        "\n",
        "Меняется состав моделей: вместо cb + lgb используется cb + cb_tuned (добавляется тюнинг гиперпараметров CatBoost).\n",
        "\n",
        "**Цель:** потенциально повысить качество за счёт тюнинга, но это не ухудшило результаты на тесте."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rapids-simple",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

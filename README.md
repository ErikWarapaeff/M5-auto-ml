# M5 Forecasting - Прогнозирование продаж Walmart

Этот проект посвящен решению задачи прогнозирования продаж Walmart в рамках соревнования Kaggle M5 Forecasting - Accuracy. Цель состоит в том, чтобы предсказать ежедневные продажи более чем 3000 товаров в 10 магазинах США (штаты Калифорния, Техас и Висконсин) на 28 дней вперед.

## Структура проекта

Проект разделен на три основные части, представленные в Jupyter-ноутбуках:

1.  **`M5_01_EDA.ipynb` (Разведочный анализ данных)**
    *   Загрузка и очистка данных.
    *   Визуализация временных рядов продаж на разных уровнях агрегации (штат, магазин, категория).
    *   Анализ влияния праздников и событий на продажи.
    *   Исследование корреляций и распределения цен.

2.  **`M5_02_LAMA_Baseline.ipynb` (Baseline решение на LightAutoML)**
    *   Использование библиотеки `LightAutoML` (LAMA) для быстрого построения базовой модели.
    *   Сравнение двух конфигураций LAMA:
        *   Конфигурация 1: Стандартный пресет с LightGBM.
        *   Конфигурация 2: CatBoost с подбором гиперпараметров.
    *   Результаты показали, что базовая модель на LightGBM демонстрирует отличную точность (RMSE: 0.0684 на тесте).

3.  **`M5_03_Custom_Solution.ipynb` (Кастомное решение)**
    *   Расширенное проектирование признаков (Feature Engineering): лаги (lags), скользящие средние (rolling windows), экспоненциальное сглаживание, временные признаки и взаимодействия цен.
    *   Построение кастомного ML-пайплайна на базе `scikit-learn`.
    *   Эксперименты с различными моделями и гиперпараметрами.
    *   Сравнение результатов: в данной итерации LAMA baseline показал себя лучше кастомного решения (Custom RMSE: 0.1087 vs LAMA RMSE: 0.0425), что подчеркивает эффективность инструментов AutoML для подобных задач.

## Результаты

| Модель | Test RMSE | Test MAE | Test R2 |
| :--- | :--- | :--- | :--- |
| **LAMA Baseline (Best)** | **0.0425** | **0.0140** | **0.9997** |
| Custom Solution | 0.1087 | - | - |

*Примечание: Результаты могут варьироваться в зависимости от объема выборки и используемых признаков.*

## Как запустить

### 1. Подготовка окружения
Проект оптимизирован для работы с GPU. Для ускорения обработки данных используются библиотеки RAPIDS (`cudf`, `cuml`). Убедитесь, что у вас установлен Python 3.11 и драйверы CUDA 12.x.

Вы можете установить зависимости с помощью:

```bash
pip install -r requirements.txt
```

Основные зависимости:
*   `lightautoml` — для автоматического построения ML-моделей.
*   `cudf`, `cuml` (RAPIDS) — для ускоренной обработки данных на GPU.
*   `lightgbm`, `catboost`, `xgboost` — основные градиентные бустинги.
*   `pandas`, `numpy`, `scikit-learn` — стандартный стек для Data Science.

### 2. Данные
Данные для соревнования можно скачать на Kaggle: [M5 Forecasting - Accuracy Data](https://www.kaggle.com/competitions/m5-forecasting-accuracy/data).

Поместите файлы данных (`sales_train_evaluation.csv`, `calendar.csv`, `sell_prices.csv`) в корневую директорию проекта.

### 3. Запуск ноутбуков
Рекомендуется запускать ноутбуки в следующем порядке:
1.  Выполните `M5_01_EDA.ipynb` для ознакомления с данными.
2.  Запустите `M5_02_LAMA_Baseline.ipynb` для получения базового результата.
3.  Изучите `M5_03_Custom_Solution.ipynb` для ознакомления с методами ручного проектирования признаков.
